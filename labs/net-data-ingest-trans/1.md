# Network data ingestion process into DLP


# **Introduction about ingestion of network data in real-time using Kafka in Hadoop platform**

Computer network is a telecommunication process which allows computers or devices to exchange data between each other using data pipeline and those devices are controlled by wired or wireless medium. Those devices are keep alive by exchanging data between each other in a continuous way. 
</br>
These network data provides the inside details detail about health and communication performance between of two devices which are communicating. We can extract lots of valuable information from those data set if we can capture those data in real time way. 
</br>
Below example will provide a way to learn the process of ingesting network data into Hadoop environment and perform transformation and extract and display values from there in a analytical tool called Tableau.
# **Lab Overview**

A data collection server, shown in the diagram below, is collecting data in real time from the local network. The data collected by the Server is working with a Client residing in DLP to transfer the network data collected through Kafka. Using Kafka socket code, we are making a connection to the client and capture the network data and send it to a Kafka topic. From this topic, data will be moved to HDFS by a Consumer program. With the data present in HDFS. The diagram shows how exactly network data flows from a local network through Kafka in HDFS. 

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/flow1.png?raw=true)

In this lab, the network stream data is generated from network traffic simulator. From DLP platform, user can access it directly. The steps for creating a network stream is described below. 

<font color='red'>Request access to the Data Learning Platform by sending a message to:</font> [datalearningplatform@cisco.com](mailto:datalearningplatform@cisco.com)

# Lab Objectives

*	How to get network data from the HDFS. 
*	Learn the process of configuring Kafka and network traffic simulator.
* Visualize network data from DLP's paltform.

# Prerequisites

*	Knowledge on Hadoop to store the network data.
*	Basic knowledge of how spark & Kafka works.
*	Chrome Browser.

# Lab Settings

<b>"Data Repository"</b> section is allowing you to create network real-time data stream. Kafka's producer will push the Network traffic generated data to Kafka cluster and Consumer will consume that data and save that into HDFS in real-time.

<b>N.B.</b>DLP platform provide a default Kafka's Producer, Consumer and Network traffic generator using network traffic simulator. User can select there own network data and use DLP provided Kafka's component to process the network data. User can define and deploy their own service also. 

# Step 1: Explore Data Learning Platform (DLP)

Workspace is a working zone for developer. 

For network data transformation task, select below mentioned workspace with sample code.

1. Click on <b>Import New Data</b> button from <b>Data Repository</b> tab.
![network-data](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/importNetworkData.PNG?raw=true)
2. It will open a entry form where user need to set the KAFKA and NTSERVER. 
![network-data](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/importNetworkData2.PNG?raw=true)
*Follow below instructions for entering details in above import data entry form.*
<b> 
name->Any text as a name </br>
Type-> It is a drop-down list box. Select <b>network</b> from the list. </br>
Select Streaming Data Processing Service -> Select default value from the list. </br>
TOPIC -> Change the topic name as <b>DDP_user_2</b>. If your login id is <b>user_2</b>. If your login if <b>user_3</b>, then the value of this field would be <b>DDP_user_3</b> </br>
Description -> Put some details about your live stream. </br>
**Keep the default value of KAFKA and NTSERVER. Don't change the text against these two fields.**


1. From "Development Hub", select pre-defined workspace called <b>"wksp-transform"</b>
2. Click on  <b>"launch"</b> button. It will open the cloud IDE on another tab.
![alk-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/WorkSpaceSelection.PNG?raw=true)
